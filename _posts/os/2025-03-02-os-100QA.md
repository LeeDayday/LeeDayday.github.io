---
title: "Operating Systems Interview Questions"

categories:
  - os
tags: [os, interviews, cs]

date: 2025-03-02
last_modified_at: 2025-03-19
---

참고 자료
[Geeks for geeks](https://www.geeksforgeeks.org/operating-systems-interview-questions/)
### 0. 운영체제란?
- 사용자와 컴퓨터 시스템 간 GUI 역할 수행
	- 사용자와 컴퓨터 하드웨어 간 메모리,  processing, power, I/O 작업등의 자원을 관리
- 운영 체제는 컴퓨터에서 실행 중인 모든 process 를 관리
	- 각 process가 processor를 사용할 수 있도록 일정한 시간을 할당
	- 각 process가 필요한 memory나 disk 같은 다양한 자원 할당
- 대표적인 운영체제로는 Windows, MacOS, Linux, Android, ... 가 있음



### 1. Process, Process Table은 무엇인가?
- Process
	- 실행 중인 program의 instance
		- 웹 브라우저, 명령 프롬프트, ...
	- OS는 process가 필요한 자원들을 할당해준다.
		- memory, disk, ...
- Process Table
	- OS는 모든 process의 상태를 추적하기 위해 Process Table을 유지
	- 각 process가 사용 중인 자원과 process의 상태가 함께 기록

### 2. Process의 State
- NEW : 새롭게 생성된 프로세스가 가지는 상태입니다.
- READY (준비 상태): 
	- 준비 큐에서 운영체제에 의해 CPU에 로드되길 기다리는 상태입니다.
		- process 가 processor 사용 준비 갈 완료
		- OS가 processor를 할당해주기만을 기다려
- RUNNING (실행 상태): 
	- CPU에 로드되어 실행 중인 상태
		- 실행에 필요한 모든 자원 보유
		- OS로부터 processor를 사용할 권한 부여 받음
		- **한 번에 하나의 Process만 실행 상태가 될 수 있음**
- WAITING (대기 상태): 
	- I/O 이벤트가 발생했을 때 해당 이벤트가 처리되는 동안, 혹은 어떤 이벤트를 기다릴 때 Device queue 에서 대기하는 상태 입니다.
		- Process가 사용자 입력이나 Disk Access와 같은 외부 이벤트가 발생하기를 기다리는 상태
- TERMINATED : 프로세스가 종료되고 CPU 에서 제거되었을 때의 상태입니다.


### 3. Thread 란?
- Process 가 수행하는 작업의 실행 단위
- **Process 내부**에서 실행되는 단일 실행 흐름(Sequence Stream)
	- Process가 할당 받은 자원을 사용하여 작업을 수행
- 병렬 처리를 통해 어플리케이션 성능을 향상시키는데 널리 사용됨
	- ex) 웹 브라우저에서는 여러 개의 tab이 각각 다른 thread로 실행될 수 있음

### 4. Process 와 Thread의 차이
- Process
	- 실행 중인 program의 instance
	- 독립적인 실행 단위. 
	- 생성 시, **자체적인 메모리 공간**을 할당 받음 (코드 / 데이터 / 힙 / 스택) 
- Thread
	- Process 내에서 독립적으로 실행될 수 있는 가장 작은 명령어 단위 (process의 일부)
	- 한 Process 내 여러 Thread를 가질 수 있으며 
	  이 Thread들은 해당 thread의 자원을 일부 공유
		- 같은 주소 공간 (코드, 데이터, 힙 (운영 체제 자원 등)) 공유
			- *stack*은 고유 영역
		- 그래서 thread를 'lightweight process'라 부르기도 함
	- *각 thread는 개별적인 Program Counter (PC), Register, Stack space를 가지므로
	  같은 process 내에서도 독립적으로 실행될 수 있음*

### 5. Multithreading programming의 장점
- System의 반응성을 높이고 자원 공유를 가능하게 함
	- process 내부에 있는 thread는 *heap 영역을 공유*하기 때문에 thread끼리 공유 용이
	- 서로 공유하는 영역이 많기 때문에 CPU cache hit rate이 높아 
	  Multi processing 보다 context switching cost down⬇️
- Multiprocess architecture를 활용할 수 있도록 하며, 더 경제적이고 선호되는 방식


### 6. Thrashing 이란?
- 컴퓨터의 성능이 급격히 저하되거나 마비되는 현상
- 시스템이 실제 작업을 수행하는 시간보다 Page Fault를 처리하는 데 더 많은 시간을 소모할 때 발생
	- Page Fault - 가상 메모리의 장점을 활용하기 위해선 필수적이로 처리해야 함
- Page Fault 율이 급격히 증가하면 시스테 성능에 부정적인 영향을 미침
	- 더 많은 transaction 이 Paging Device에서 처리되어야 함
		- Paging Device의 queue가 길어짐
			- Page Fault의 서비스 시간 증가
				- 전체적인 성능 저하

### 7. Buffer 란?
- 두 장치 간 또는 장치와 application 간에 전송되는 데이터를 임시로 저장하는 메모리 영역 (**임시 저장소**)
- 주로 입출력 (I/O) 속도를 맞추거나 데이터 흐름을 조절하는데 사용
	- ex)
	  키보드를 빠르게 입력하면 OS가 이를 buffer에 저장한 후, 일정한 속도로 프로그램에 전달함
- Network 통신, 파일 입출력, 스트리밍에서도 데이터를 일정량 모아서 보내는 역할을 함


### 8. Virtual Memory란?
- 각 사용자가 연속적인 주소 공간을 가지고 있는것처럼 보이게 하는 기술
	- 각 주소는 0번지부터 시작하는 것처럼 보이지만,
	  실제로는 물리적 메모리 (RAM) 보다 훨씬 큰 크기를 가질 수 있음
- **디스크 공간을 이용하여 RAM을 확장**
	- 실행중인 process는 사용중인 memory가 RAM인지 Disk인지 신경쓸 필요 없이,
	  OS가 필요한 부분만 물리적 메모리로 로드하여 실행할 수 있도록 함
	- 가상 주소 공간을 작은 단위 (*page*) 로 나누어 필요할 때만 물리적인 메모리에 적재
		- 제한된 RAM보다 훨씬 효율적으로 사용 가능
---
- OS는 Program이 요청한 데이터나 코드가 RAM에 없는 경우 이를 감지하고
  Disk에서 해당 부분을 가져와 RAM에 적재  수행 (**Page Fault** 처리)
- **RAM을 효율적으로 관리: 필요할 때만 Disk에서 RAM으로 가져오기, 필요없으면 다시 Disk로**


### 9. OS의 주요 목적
- User와 Computer Hardware 간의 중개자 역할
	- User가 program을 편리하고 효율적으로 실행할 수 있는 환경을 제공하는 것
- OS는 Computer Hardware를 관리하는 Software
	- Hardware는 Computer system이 올바르게 작동하도록 적절한 제어 메커니즘을 제공,
	  user program이 system의 정상적인 작동을 방해하지 않도록 보호해야 함

### 10. Demand Paging 이란?
- OS에서 memory 사용을 최적화하고 시스템 성능을 향상시키기 위한 메모리 기법
	- Page Fault가 발생할 때마다 필요한 Page를 Memory에 로드하는 과정을 의미
		- *Page Fault*: 현재 실행중인 process가 필요로 하는 메모리 자원이 RAM에 없을 때 발생하는 이벤트
	- **Page를 미리 memory에 로드하지 않고, 필요할 때만 올려 사용. 필요하지 않은 page는 보조 기억 장치 (Disk)에 유지**

### 11. Kernel 이란?
- Operating Systems의 중심 구성 요소
- 컴퓨터와 하드웨어의 동작을 관리
	- Memory, CPU 시간의 운영 관리, ...
- Application과 하드웨어 수준에서 수행되는 데이터 처리 간의 다리 역할
- *IPC (Inter Process Communication, 프로세스간 통신)* 및 *System Calls (시스템 호출)* 을 사용하여 상호작용

### 12. 다양한 Scheduling Algorithms
- OS 는 CPU를 효율적으로 할당하기 위해 Scheduling Algorithms를 사용
- **FCFS (First-Come, First-Served) Scheduling**
	- 가장 먼저 도착한 process부터 처리
	- 가장 단순한 방식
	- *긴 프로세스가 먼저 실행되면 대기 시간이 길어지는 문제 발생* (Convoy Effect)
- **SJN (Shortest-Job-Next) Scheduling**
	- 실행시간이 가장 짧은 작업을 우선 실행
	- 평균 대기 시간이 짧아지는 장점
	- *실행 시간이 긴 프로세스가 계속 밀릴 수 있어 기아 현생 발생 가능* (Starvation)
- **Priority Scheduling**
	- 각 process에 우선순위 값을 부여하고, 높은 우선순위의 process를 먼저 실행
	- 긴급한 작업을 먼저 처리할 수 있음
	- *낮은 우선순위의 작업이 계속 밀릴 수 있음* (Starvation)
			- *Aging* 기법을 사용하여 Starvation 방지 가능
- **SRT (Shortest Remaining Time) Scheduling**
	- 현재 실행 중인 process와 비교하여, 실행 시간이 더 짧은 process가 도착하면 교체 (Preemptive)하여 실행
	- SJN 의 선점형 (Preemptive) 버전
	- 더 짧은 작업이 계속 들어오면 긴 작업이 계속 밀릴 수 있음 (Starvation)
- **RR (Round Robin) Scheduling**
	- 각 process에 동일한 시간 할당 (Time Quantum) 을 주고, 순환하며 실행
		- 모든 process가 일정한 시간마다 CPU를 할당받을 수 있음
		- *Time Quantum이 너무 크면  -> FCFS 같음
		  Time Quantum이 너무 작으면 -> Context Switching Overhead가 커짐*
- **Multiple-Level Queues Scheduling**
	- process를 여러 개의 Queue로 분류. 각 Queue에 다른 Scheduling Algorithms 적용
	- 실시간 process (높은 우선순위) 와 일반 사용자 process (낮은 우선순위)를 분리하여 관리 가능
		- 즉, Process의 특성에 따라 Queue 를 나누어 효율적으로 관리 가능
	- Queue 간 이동이 가능한 Multi-Level Feedback Queue 도 있다

### 13. Multi-Programming의 목적
- Organize Job (코드와 데이터를 정리)하여 CPU가 항상 실행할 작업을 갖도록 하여 **CPU 활용도** (CPU Utilization) 향상
- 주요 목적
	- 여러 개의 작업을 Main Memory (**RAM**)에 유지하는 것
	- 하나의 작업이 I/O 작업으로 인해 대기 상태에 들어가면, CPU가 다른 작업을 실행하도록 할당
		- CPU가 Idle State (유휴 상태) 로 들어가지 않도록

### 14. Time-Sharing System이란?
- Multi-Programming의 확장 개념
- CPU가 매운 빠른 속도로 작업을 전환 (Switching) 하여 여러 작업을 동시에 실행하는 것처럼 보이게 함
- Time-Sharing Operating System은 여러 사용자가 동시에 컴퓨터를 공유할 수 있도록 하며,
  각 사용자는 실행 중인 프로그램과 실시간으로 상호작용 가능

### 15. Computer System에 OS가 없다면?
- 자원 관리 부족 (Poor Resource Management)
	- CPU, Memory, Disk 등의 자원을 효율적으로 관리할 수 없음
	- 여러 프로그램을 동시에 실행하는 것이 어려워짐
- 사용자 인터페이스 부재 (Lack of User Interface)
	- GUI, CLI 제공 x
	- 사용자가 컴퓨터와 직접 상호작용할 수 없음
- 파일 시스템 없음 (No File System)
	- 파일을 저장/수정/삭제 하는 파일 시스템 제공 ㅌ
	- 데이터를 구조화하여 관리하는 것이 불가능해짐
- 네트워킹 기능 없음 (No Networking)
	- 인터넷 및 네트워크 연결 관리 불가
- 오류 처리 불가능 (Error Handling)
	- 프로그램 충돌, 메모리 오류 등 감지 + 복구 수행 불가
	- 에러를 처리할 수 없어 시스템이 쉽게 중단될 가능성이 높아짐

### 16. Multithreading Programming 의 장점
- Thread 는 lightweight process (경량 프로세스) 라고도 불림
- Multithreading Programming의 핵심 개념은 하나의 process를 여러 개의 thread로 나누어 병렬성을 달성하는 것
- 같은 process 내 thread들은 공유 메모리 공간에서 실행 됨

### 17. FCFS scheduling algorithm 이란?
-  Scheduling Algorithms
- 먼저 온 순서대로 (First Come First Served).
	- Ready Queue에 먼저 도착한 작업이 CPU를 할당받고 실행.
	  그 다음에 도착한 작업이 순차적으로 실행
- 비선점형 (Non-Preemptive)
	- 한 process가 CPU를 할당받으면 작업이 끝나거나 
	  I/O 작업을 수행할 때까지 CPU 계속 점유
- 한계
	- 실행 시간이 긴 작업이 먼저 할당되면, 그 뒤에 있는 짧은 작업들이 오랫동안 대기해야하는 문제 발생 가능

### 18. RR scheduling algorithm 이란?
- 각 process에게 **공평하게 CPU 시간을 할당**
	- 정해진 시간(Time Quantum) 동안 실행
	- 해당 시간이 지나면, 작업이 완료되지 않았더라고, CPU 를 다음 process로 넘기고
	남은 작업은 queue의 뒤로 이동
- 특징
	- FCFS에서 시간 할당 개념이 추가된 구조
	- 모든 process가 동일한 우선순위를 가짐
	- Time Slicing Scheduling 라고도 함
	- Starvation 발생 X (순환 방식이어서)

### 19. 다양한 RAID(level) 종류
- RAID(Redundant Array of Independent Disks, 중복 배열 독립 디스크)는 여러 개의 물리적 Disk Drive를 Operating Systems에서 하나의 논리적 장치로 인식하도록 구성하는 기술
- 빠른 Processor, 느린 Disk Drive 간의 성능 차이를 줄이는 역할
- 0 ~ 6까지의 level 존재
	- level이 높을 수록 보호 기능 강화 & 저장 효율 감소 경향


### 20. Bankers 알고리즘이란?
- 자원 할당 및 Deadlock 회피를 위한 Alg
- 모든 process가 필요로 하는 최대 자원량을 미리 파악한 뒤,
  그 자원들을 할당한다고 가정하여 시스템이 safe state에 있는지 시뮬
- 그 후, **안전성 검사 (s-state check)** 을 수행하여
  모든 process가 deadlock 없이 실행될 수 있는 경우에만 자원 할당 허용


### 21. 논리 주소 공간(Logical Address)와 물리 주소 공간(Physical Address)의 주요 차이점

| 구분 | 논리 주소 (Logical Address) | 물리 주소 (Physical Address) |
| --- | --- | --- |
| 기본 | CPU에 의해 생성 | 실제 메모리 장치에 에 위치 |
| 주소 공간 | CPU가 생성한 모든 주소의 집합 | 논리 주소와 매핑되는 실제 주소의 집합 |
| 가시성 | O | X |
| 생성 주체 | CPU | MMU (Memory Management Unit) |
| 사용자 접근 가능 여부 | 논리 주소를 사용해서 물리 주소에 접근 가능 | 물리 주소에 직접 접근 X |

- 논리 주소: process 가 보는 memory address (즉, 가상 주소)
- 물리 주소: 사용자가 직접 접근할 수 없으니, OS가 중간에 대신 처리해야 함
- => process 는 진짜 위치 (Physical Address) 를 신경 쓸 필요 없고, process가 아는 주소 (Logical Address) 만 사용 -> OS가 알아서 진짜 위치에 mapping

### 22. Dynamic Loading이 메모리 공간 활용을 어떻게 향상시키는가?
- 특정 routine (function / code block) 은 실제로 호출되기 전까지 memory에 load되지 않음
- 오류 처리 routine처럼 드물게 사용되는 대용량 code가 있을 경우 특히 유용
- **필요한 시점에만 memory에 적재**하므로, 전체 program이 한꺼번에 memory를 차지하지 않아 memory 공간을 더 효율적으로 사용 가능

### 23. Overlays 란?
- 현재 필요한 부분만 memory에 load
- 해당 부분의 실행이 끝나면 그 부분을 memory에서 제거한 뒤, 다음 실행에 필요한 부분을 다시 load
- memory가 제한된 환경에서 큰 program을 효율적으로 실행할 수 있게 해줌

### 24. Fragmentation이란?
- process가 memory가 저장되었다가 제거되는 과정에서 **작은 크기의 빈 memory 공간들이 여기저기 흩어져 생기게 됨**
	- 이러한 빈 공간들은 너무 작아서 다른 process가 사용하기 적합 X
	- **사용되지 못한 채 남아있게 되는 현상: Fragmentation**
- memory block의 크기가 너무 작아서 어떤 요청도 수용할 수 없을 때 발생하는 문제
- 주로 *dynamic memory allocation* 환경에서 여러 요청과 해제가 반복될 때 자잘한 빈 공간들이 생기면서 발생

### 25. Paging의 기본 기능은?
- 비연속적인 (Non-Contiguous) Memory 할당을 위한 기법
	- 고정 크기 분할 방식 (fixed-size partitioning scheme)을 사용
	- Secondary Memory에 있는 Process를 Main Memory로 가져올 때 사용되는 memory 관리 방식
	- 각 process가 동일한 크기의 block (page) 단위로 분할
	- 마지막 block은 page 크기보다 작을 수 있음
	- 분할된 process의 page는 사용 가능한 frame에 따라 main memory에 저장됨
- *Main Memory*와 *Secondary Memory*를 동일한 크기의 block으로 나눔
	- Main memory의 block: **Frame**
	- Secondary memory의 block: **Page**

### 26. Swapping은 어떻게 더 나은 Memory 관리를 가능하게 할까?
- Swapping
	- OS가 사용하는 간단한 Memory/Process 관리 기법
	- Processor의 활용도를 높이기 위해 blocked 된 일부 process를 Main Memory -> Secondary Memory로 이동시키는 방식
- 일시적으로 중단된 Process들을 Secondary Memory에 대기시키는 Queue를 만들고, 그 사이에 도착한 새로운 process를 실행함으로써 전체적인 실행 흐름을 유지
- OS가 설정한 일정한 주기마다, Process는 Main Memory에서 Backing Store (백업 저장소)로 복사되었다가, 나중에 다시 복원되어 실행될 수 있음
- **Swapping을 통해 한 번에 Memory에 적재할 수 있는 Process 수보다 더 많은 Process를 실행 가능하게 하여 Memory 활용도를 향상시킬 수 있음**

### 27. 고전적인 Synchronization 문제
- Synchronization (동기화): 공유 자원에 여러 process/thread가 동시에 접근할 때, 충돌이나 예기치 못한 에러 없이 일관된 결과를 유지하도록 제어하는 것

- **Bounded-Buffer Problem (한정 버퍼 문제)**
	- **생산자-소비자**문제로도 알려짐

	- | 생산자 | 소비자 | 
	| -- | -- | 
	| data를 buffer에 넣는다 | buffer에서 data를 꺼낸다 |
	- buffer의 크기는 제한되어 있음
		- *buffer가 가득 찼을 땐 생산자가 대기, buffer가 비어있을 땐 소비자가 대기해야 함*
	- ➡️ **버퍼의 공백 여부에 따라 동기화 필요**

- Readers-Writers Problem (읽기-쓰기 문제)
	- DB 등의 공유 자원에 대해 여러 Process가 동시에 접근 시
	여러 READ process 는 동시에 접근 가능하지만, WRITE process는 단독으로 접근해야 함
	- ➡️ **READ 와 WRITE 사이의 동기화가 핵심**
	
- **Dining Philosophers Problem (철학자 식사 문제)**
	- 원형 테이블에 앉아있는 철학자, 각자 양쪽에 포크가 있음 (*=공유자원*)
	- 식사를 하려면 양쪽 포크를 모두 들어야 함
	- 동시에 포크를 잡으려다 보면 **Deadlock** 발생 가능
	- ➡️ **Deadlock, Starvation, Synchronization 문제의 전형적인 예시**

- Sleeping Barber Problem (잠자는 이발사 문제)
	- 이발사: 손님이 없으면 잠든다, 손님이 오면 깨서 이발한다.
	- 손님: 대기실 의자에서 대기. 자리가 없으면 대기하지 않고 돌아감.
	- ➡️ **이발사와 손님사이의 동기화, 제한된 대기 자원이 핵심**

| 공통점 |
| -- |
| 모두 **공유 자원에 대한 동시 접근**이 있을 때 발생할 수 있는 문제 |
| **Mutex, Semaphore, Condition Variable** 와 같은 동기화 도구 필요 |

### 28. 직접 접근 방식 (Direct Access Method, DMA)란
- 파일을 디스크 모델 기반으로 간주하여 파일을 번호가 매겨진 블록 또는 레코드의 연속적인 집합으로 보는 방식
- 이 방식은 임의의 블록을 자유롭게 읽거나 쓸 수 있도록 허용하며, 대용량 데이터를 빠르게 접근할 떄 유리
- I/O 장치가 CPU를 거치지 않고, 직접 Main Memory와 data를 주고받을 수 있도록 하는 방법
	- 메모리 연산을 더욱 빠르게 처리할 수 있도록 설계
	- 이 과정을 관리하는 전용칩: DMAC (Direct Access Method Controller)

### 29. Thrashing 은 언제 발생할까?
- system의 process들이 자주 접근하는 page가 실제 memory에 존재하지 않을 때 발생
	- 이로 인해 OS가 Memory 와 Disk 사이에서 Page를 계속 교체하느라 바빠짐
		- 실제 작업을 거의 수행하지 못하는 상태가 됨 (**=Thrashing**)

### 30. OS를 설계할 때 가장 좋은 Page Size는?
- Page Size는 system마다 다르기 때문에, 단 하나의 "최적의 크기"는 존재하지 않음!
- Page Size를 결정할 때 필요한 고려 사항
	- Page Table의 크기
	- Paging 시간
	- 전체적인 OS 효율성에 미치는 영향
	- ...

### 31. Multitasking 이란?
- Multiprogramming 의 논리적인 확장 개념
	- 여러 program이 동시에 실행될 수 있도록 지원하는 방식
	- 2개 이상의 task(process)를 동시에 실행
		- CPU와 같은 공통 처리 자원을 함께 공유
- 즉, 하나의 CPU가 여러 작업을 짧은 시간 단위로 빠르게 번갈아가며 실행
	- 사용자 입장에서는 여러 작업이 동시에 이루어지는 것처럼 보이게 만드는 기술

### 32. Caching 이란?
- Cache 는 자주 사용되는 Main Memory의 데이터를 저장해두는 더 작고 빠른 memory
- CPU 내부에는 명령어와 data를 저장하는 다양한 독립적인 Cache들이 존재
- Cache Memory 는 Main Memory로부터 data를 접근하는 평균 시간을 줄이기 위해 사용

### 33. Spooling이란?
- Simultaneous Peripheral Operations Online
	- 주변 장치들이 시스템에 연결된 상태에서 동시에 작업을 처리할 수 있도록 하는 기술
- 작업들을 버퍼 (Memory / Disk의 특수한 영역 / ...) 에 저장해두고, 주변 장치가 준비되었을 때 해당 데이터를 접근하도록 함
	- 특정 장치를 제어하는게 아니라, 데이터를 "어떻게 넘기고 기다릴 것인가"를 정의하는 하나의 처리 방식
- 장치마다 data를 처리하는 속도가 다르기 때문에 유용
	- 프린터 출력 시 문서를 한꺼번에 프린터로 보내는 것이 아니라, 프린터 큐에 쌓아두고 프린터가 하나씩 처리
		- 해당 구조 또한 **spooling**의 예시

### 34. Assembler의 기능은?
- Assembler는 Assembly language 로 작성된 프로그램을 Machine code로 번역하는데 사용
- Assembler 의 input: Assembly language가 포함된 source program
- Assembler 의 output: 컴퓨터가 이해할 수 있는 object code / machine code

### 35. Interrupts 란?
- Hardware나 Software에서 즉각적인 주의가 필요한 process 나 event가 발생했을 때 발생시키는 신호
	- 현재 작업 중인 process를 중단하고, 우선순위가 높은 작업을 처리하라는 알림을 processor 에게 보냄
	- I/O 장치의 경우, bus control lines 중 하나가 이 목적을 위해 전용으로 사용됨 (Interrupt Service Routine, ISR)

### 36. GUI 란?
- Graphical User Interface
- 아이콘, 그래픽 심볼을 이용해 사용자와 시스템 간 상호작용이 가능하도록 해주는 인터페이스 제공
- 사용자는 명령어를 직접 입력하는 대신 그래프 요소를 클릭하거나 조작함으로써 작업을 수행

### 37. Preemptive Multitasking 이란?
- Preemptive Multitasking (선점형 멀티태스킹) 은 컴퓨터 program 들이 OS 와 Hardware 자원을 공유할 수있도록 하는 Multitasking 방식
- 전체 실행 시간과 계산 시간을 여러 process 간 분할
- 자원 전환은 미리 정의된 기준 (타이머/ 우선 순위/ ...) 에 따라 자동으로 이루어짐
- 즉, 하나의 process 가 CPU를 너무 오래 점유하지 못하도록 하고, OS가 강제로 제어권을 회수하여 다른 process에 할당
	- => 시스템 전체의 응답성과 공정성 확보

### 38. Pipe란 무엇이고, 언제 사용될까?
- Pipe는 process 간 통신 (IPC, Inter-Process Communication) 을 위한 기술
- 한 process의 출력 결과를 다른 process의 입력으로 전달할 수 있음
	- process 간 data를 한 방향으로 흐르게 하는 통로 역할

### 39. Semaphore의 장점
- machine-independent (특정 Hardware 나 system 에 의존하지 않고 작동 가능)
- 쉬운 구현
- 정확성을 판단하기 쉬움
	- `wait()` `signal()` 두 연산만 사용
	- 원자적 (atomic)으로 수행되기 때문에 경쟁 조건 (race condition)이 발생할 가능성이 적음
	- **공유 자원에 접근하는 진입 시점/해제 시점이 명확하게 드러남**
- 여러 개의 semaphore을 사용하여 여러 critical section 을 가질 수 있음
- 여러 자원을 동시에 획득할 수 있음
- busy waiting 으로 인한 자원 낭비가 없음
	- busy waiting: CPU가 어떤 조건이 만족될 때까지 다른 일을 하지 못하고 계속 loop를 돌며 기다림

### 40. OS에서 bootstrap program은 무엇일까?
- Bootstrapping은 컴퓨터가 처음 켜질 때 일련의 명령어를 load하는 과정
	- 전원 자가 테스트 (POST, power-on-self-text) 같은 진단 테스트 수행
	- 장치 설정을 확인하거나 구성. 주변 기기나 하드웨어, 외부 메모리 장치와의 연결 상태 점검
	- 이후 bootstrap program이 로드되어 OS를 초기화

